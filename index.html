<!DOCTYPE html>
<html lang="en">
<head>

    <!-- Basic Page Needs
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <meta charset="utf-8">
    <title>Memory Reduction</title>
    <meta name="description" content="">
    <meta name="author" content="Theo Jaunet, Romain Vuillemot and Christian Wolf">
    <meta property="og:title" content="Memory Reduction — What if we Reduce the Memory of an Artificial Doom Player?">
    <meta property="og:description" content="We built Doom player AI using Deep Reinforcement learning. While playing, it builds and updates an inner representation (memory) of the game, its environment.
    Reducing this memory could help the player learning to complete its task and thus lower both its training time and energy consumption footprint.">
    <meta property="og:image" content="https://theo-jaunet.github.io/MemoryReduction/assets/screenshot.png">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-105697527-4"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());
        gtag('config', 'UA-105697527-4');
    </script>

    <!-- Mobile Specific Metas
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- FONT
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <link href="//fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">

    <!-- CSS
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->

    <link rel="icon" href="assets/favicon.ico"/>

    <link rel="stylesheet" href="css/normalize.css">
    <link rel="stylesheet" href="css/skeleton.css">
    <link rel="stylesheet" href="css/custom.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <script src="https://d3js.org/d3.v5.min.js"></script>

    <script src="js/rough.js"></script>

</head>
<body style="overflow-y: hidden">

<div style="position: absolute; min-width: 1245px; margin-left: auto;margin-right: auto;left: 0;right: 0;max-width: 1500px;text-align: center" id="intro">
    <div style="margin-top:30px "><h2>What if we Reduce the Memory of an Artificial Doom Player?</h2></div>
    <img src="assets/demo.gif" style="width: 80%;margin-top: 25px; height: auto">
    <div style="font-size: 26pt;margin-top: 15px">Check it at: <span style="text-decoration: underline">theo-jaunet.github.io/MemoryReduction</span></div>

</div>


<!-- Primary Page Layout
–––––––––––––––––––––––––––––––––––––––––––––––––– -->
<div class="container" style="position: relative; min-width: 1245px;padding: 0; visibility: hidden;  scrollbar-width: none;height: 1000px;overflow-y: hidden" id="fig_main">

<svg style="position: absolute; width: 300px;height:643px;top:128px;right: -112px " id="memcom">

</svg>
    <div class="row" style="margin-top: 12px;max-width: 1600px">
        <div class="seven  columns" style="position: relative;width: 650px">
            <h5> What if we Reduce the Memory of an Artificial Doom Player?</h5>

            <div>


            </div>


            <p id="order" style="max-height: 100px;width: 490px;margin-top: 10%;margin-left: 157.5px">


                <img src="assets/armorGreen.png" class="item-icon" height="57px"> <img src="assets/arrow.png" class="arrow-icon">
                <img src="assets/armorRed.png" class="item-icon"> <img src="assets/arrow.png" class="arrow-icon">
                <img src="assets/hp.png" class="item-icon"> <img src="assets/arrow.png" class="arrow-icon">
                <img src="assets/soul.png" class="item-icon" style="width: 36px">

            </p>

        </div>
        <div class="five columns" style="margin-left: -6px; width: 600px">
            <div class=" nav left-card-arr button" style="display:none; vertical-align: bottom;"><p style="padding: 13px 0px"> < </p></div>
            <div index="0" class=" nav selected card button"><p> Full Memory <br> (no reduction) </p></div>
            <div index="1" class=" nav card button"><p>Random <br> Reductions</p></div>
            <div index="2" class=" nav card button"><p>Top Elements <br> only</p></div>
            <div index="3" class=" nav card button"><p>Selection of <br> Reductions</p></div>
            <div index="4" class=" nav card button"><p>Do it <br>Yourself</p></div>
            <div class=" nav right-card-arr button" style="display:none;"><p style="padding: 13px 0px;font-weight: 700"> > </p></div>
        </div>
    </div>
    <div style="width: 360px;position: absolute;right: 22px;top: 86px">
        <!--<h5 style="width: 100%;margin-left: 85px" id="card_title"> Full Memory</h5>-->
        <!--<p id="card_txt" style="margin-top: -11px;width: 100%">-->
        <!--</p>-->
        <!--<svg id="sco" style="width: 150px;height: 150px;position: absolute;right: 109px;bottom: -160px;z-index: 777;visibility:hidden"></svg>-->
        <!--<div id="nextarr" onclick="$('.right-card-arr').trigger('click')"-->
        <!--style="cursor:pointer;position: absolute;right: 28px;bottom: 12px;z-index: 777"><a>Next <img src="assets/arrow.png" class="arrow-icon"> </a>-->
        <!--</div>-->
        <div id="credits" style="visibility: hidden;margin-top: 100px;margin-left: 100px">
            <h5><span style="text-decoration:underline;font-weight: 500">Théo Jaunet</span><br>LIRIS, INSA-Lyon (France) </h5>
            <h5><span style="font-weight: 500">Romain Vuillemot </span><br>LIRIS, Ecole Centrale de Lyon (France) </h5>
            <h5><span style="font-weight: 500">Christian Wolf </span><br>LIRIS, INSA-Lyon, CITI, INRIA (France) </h5>
        </div>

    </div>

    <div class=" row" style="max-height: 665px;position: absolute;top:120px;text-align: center;margin-left: auto;margin-right: auto;left: 0;right: 0" id="svg_div">

        <div style="width: 35px;height: auto;display: inline-block;margin-right: 20px;position: absolute;left: 515.7px;top: 1.6px;z-index: 50;margin-left: 122.5px" id="inf">
            <!--<img class="play" style="width: 29px;position: absolute;left: 90px;top:-53px" src="assets/play-sign.svg">-->
            <input id="timebar" type="range" min="0" max="66" step="1" value="0"
                   style="width: 407.5px;position: absolute;top: -6px;left: 11.9px">
            <p id="stepctn"
               style="position: absolute;display: inline-block;left: 170px;width: 88px;top: -42px;user-focus: none;user-select: none">
                Step --/--</p>
        </div>
        <div>
            <canvas id="input" style="position: absolute;bottom: 18px;width: 331.5px;height: 188.5px"></canvas>
            <svg class="" id="svg-tool" style="height: 663px;width: 1000px !important;">
                <defs>
                    <filter id="brightness">
                        <feComponentTransfer>
                            <feFuncR type="linear" slope="2"/>
                            <feFuncG type="linear" slope="2"/>
                            <feFuncB type="linear" slope="2"/>
                        </feComponentTransfer>
                    </filter>
                    <linearGradient id="linear-gradient" gradientTransform="rotate(0)">
                        <stop offset="0%" stop-color="rgba(10,10,10,1)"></stop>
                        <stop offset="0%" stop-color="rgba(10,10,10,0)"></stop>
                    </linearGradient>
                </defs>
            </svg>
            <div style="font-size: 21pt;margin-top: 24px">Check it at: <span style="text-decoration: underline">theo-jaunet.github.io/MemoryReduction</span></div>
        </div>

    </div>

</div>


<!--<div class="container" style="min-width: 1200px;text-align: center;visibility: hidden">

    <div class=" row" id="scrolltxt" style="text-align: center;margin-top: 550px">
        <div class=" twelve columns" style="margin-top: 15%;display: inline-block">
            <div style="text-align: left;width: 800px;display: inline-block">
                <h4>Deep Reinforcement Learning and Memory</h4>

                <p> We used the Advantage Actor Critic (A2C) method, as presented by <i><a
                        href="https://arxiv.org/abs/1904.01806"> E.Beeching et. al. </a> </i>.
                    This model learns through trial and error to associate an observation (i.e. matrice of pixels), at
                    the time-step t to an action (at) such as turn left.
                    It can achieve this by using neuronal networks with shared parameters <i>theta.</i>
                </p>

                <p>
                    The model is composed of three stages with different purposes.
                    First, 3 convolutional layers to analyze and extract features from the input game screen
                    (image).
                    This results in a tensor of 16 features <i>(ft)</i> shaped as 10x4 matrices. Those features are then
                    flattened into a vector of 1x32 using a Fully Connected layer.
                    The purpose of such operation is to prepare them for the next stage, which is the memory.
                </p>
                <p>
                    The memory of such model is handled by a GRU layer, which takes a vector as input and outputs a
                    hidden state <i>(ht)</i>, a vector of 32 elements.
                    GRU layers maintain and update a latent representation through time-steps using the combination of
                    its current input <i>(ft)</i> and its previous hidden state <i>ht-1</i>.
                    Each element of the hidden states is a quantity within the range[−1,1]. A value close to 0
                    represents low activity, whereas a value close to any extremity represents high activity.
                    Hidden states can change their values between two time-steps. Such value changes can be widely
                    observed across hidden states elements during trajectories.
                    However, it remains unclear which elements correspond to which representations, and thus are
                    responsible for decisions.

                    Finally, the last stage consists of mapping the current hidden state <i>h_t</i> to a probability
                    distribution over the 5 available actions <i>(right, left, forward, forward+right, forward+left)</i>.
                </p>

                <p> During the training phase, the agent is forced to explore its environment with random actions and
                    can recieve rewards depending on their outcome:
                    +0.5 for gathering an item in the right order (armor -> health pack -> soul-sphere), and -0.25 for
                    gathering the wrong item.
                    The combination of the observation, action and reward ordered by time-steps <i>t</i> forms a rollout
                    which is then used to optimize the neural network with gradient descent.
                </p>

                <p> For a more detailed introduction to sequential memory, we recommend reading <a
                        href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/"> Christopher Olah's blog</a>
                    on LSTMs, and the <a href="https://arxiv.org/abs/1412.3555">GRU paper </a>.
                    We also recommend <a href="http://karpathy.github.io/2016/05/31/rl/">Karpathy's blog </a> for an introduction to Deep Reinforcement Learning </p>
            </div>
        </div>

    </div>

    <div class=" row" style="text-align: center">
        <div class="twelve columns" style="margin-top: 2%;display: inline-block">
            <div style="text-align: left;width: 800px;display: inline-block">
                <h4> Why Manipulating the Memory?</h4>
                <p>
                    As detailed in the previous section, the agents actions are directly linked to its memory,
                    therefore,
                    each of its decisions depend on its current hidden state <i>ht</i>, and its values.
                    However, such memory is hard to understand due to the fact that it is time-varying and using
                    numerical values.
                    Being able to erase memory elements, and to observe how the agent behaves without them,
                    may help understanding and interpreting their roles in the decision process and information they may
                    represent.

                    In addition, the hidden states length is manually set by the model's designer, therefore such values
                    maybe unfit to the agent's needs, which may results in unused or redundant elements.
                    Removing them, and thus reducing the memory length can reduce the computation power needed by the
                    agent, and both reduce the training time and the energy consumption footprint.

                </p>
            </div>
        </div>
    </div>

    <div class=" row" style="text-align: center">
        <div class="twelve columns" style="margin-top: 2%;display: inline-block">
            <div style="text-align: left;width: 800px;display: inline-block">
                <h4> How do we Erase Memory Elements?</h4>

                <p> In order to simulate a reduced memory we implemented a method that allows to generate trajectories
                    from agents with limited memory.
                    Technically, we hijack the memory vectors by applying a mask to them before each decision.
                    This mask is a 1x32 vector, with its values either set to 0 (remove the element) or set to 1 (keep
                    the element).
                    Each memory element is multiplied by its corresponding mask element, and therefore either have
                    values as they should, or values constantly equal to 0 (i.e., inactive).
                    The outcome of such operation is then used by the model to decide which action it should do.
                    This method allows to change the agent's memory without having to retrain a model.
                </p>

                <p> But how can we select which elements should be erased and those to preserve?</p>

            </div>
        </div>
    </div>

    <div class="row" style="text-align: center">
        <div class="twelve columns" style="margin-top: 2%;display: inline-block">
            <div style=" text-align: left;width: 800px;margin-bottom: 50px;display: inline-block">
                <h4>Implementation</h4>
                <p> This project uses the JavaScript library <a href="https://d3js.org/">d3</a> to display data extracted from the Deep Reinforcement Learning model implemented in Python using <a href="https://pytorch.org/">PyTorch</a>. The
                    video game DOOM is simulated with <a href="http://vizdoom.cs.put.edu.pl/">ViZDoom</a>. In addition, this project uses our previous work DRLViz (<a href="https://github.com/sical/drlviz">GitHub</a>, <a
                            href="https://sical.github.io/drlviz/">demo</a>, <a href="https://arxiv.org/abs/1909.02982v1">paper</a>) to analyse
                    and generate episodes. For more information on this project, please feel free to visit our <a href="https://github.com/Theo-Jaunet/MemoryReduction">GitHub</a>. </p>

            </div>

        </div>
    </div>

    <div class="row" style="text-align: center">
        <div class="twelve columns" style="margin-top: 2%;display: inline-block">
            <div style=" text-align: left;width: 800px;margin-bottom: 50px;display: inline-block">
                <h5>Authors</h5>
                <p><a href="https://theo-jaunet.github.io/">Théo Jaunet</a>, <a href="http://romain.vuillemot.net/">Romain Vuillemot</a> (<a href="https://twitter.com/romsson">@romsson</a>) and <a
                        href="https://perso.liris.cnrs.fr/christian.wolf/">Christian Wolf </a>(<a href="https://twitter.com/chriswolfvision">@chriswolfvision</a>), at LIRIS lab Lyon - France.</p>
                This work takes place in Théo jaunet's Ph.D. which is supported by a French Ministry Fellowship and the <a href="https://projet.liris.cnrs.fr/mi2/"> M2I project</a>,
            </div>

        </div>
    </div>

</div>-->
<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>

<script src="js/utils.js"></script>
<script src="js/drawVector.js"></script>
<script src="js/observation.js"></script>
<script src="js/distributionV2.js"></script>
<script src="js/trajectory.js"></script>
<script src="js/stage.js"></script>
<script src="js/slidemode.js"></script>
<script src="js/main.js"></script>
</html>
